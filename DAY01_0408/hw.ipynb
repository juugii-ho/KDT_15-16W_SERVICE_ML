{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchmetrics.functional as metrics\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.027] global loadsave.cpp:248 findDecoder imread_('../../Data/albumart/3824.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "image_path = '../../Data/albumart/'\n",
    "\n",
    "image = '3824.jpg'\n",
    "\n",
    "image_path+image\n",
    "\n",
    "cv2.imread(image_path+image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((25,25)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 366\n",
       "    Root location: ../../Data/albumart/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(25, 25), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = ImageFolder(root=image_path, transform = trans)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1990', '2000', '2010'],\n",
       " {'1990': 0, '2000': 1, '2010': 2},\n",
       " [('../../Data/albumart/1990/10291.jpg', 0),\n",
       "  ('../../Data/albumart/1990/104099.jpg', 0),\n",
       "  ('../../Data/albumart/1990/104184.jpg', 0),\n",
       "  ('../../Data/albumart/1990/10435.jpg', 0),\n",
       "  ('../../Data/albumart/1990/104673.jpg', 0)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.classes, datasets.class_to_idx, datasets.imgs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.7647, -0.7255, -0.7098,  ..., -0.9216, -0.9451, -0.9608],\n",
       "          [-0.6941, -0.6706, -0.6627,  ..., -0.8902, -0.9137, -0.9373],\n",
       "          [-0.6471, -0.6235, -0.6157,  ..., -0.8588, -0.8824, -0.9137],\n",
       "          ...,\n",
       "          [-0.7569, -0.7255, -0.7333,  ..., -0.8275, -0.8196, -0.8431],\n",
       "          [-0.8118, -0.8039, -0.7961,  ..., -0.8431, -0.8510, -0.8745],\n",
       "          [-0.8510, -0.8510, -0.8353,  ..., -0.8902, -0.8902, -0.8902]],\n",
       " \n",
       "         [[-0.7804, -0.7098, -0.6627,  ..., -0.8824, -0.9294, -0.9608],\n",
       "          [-0.6627, -0.5922, -0.5608,  ..., -0.7961, -0.8431, -0.9059],\n",
       "          [-0.5765, -0.5137, -0.4824,  ..., -0.7412, -0.7804, -0.8431],\n",
       "          ...,\n",
       "          [-0.7961, -0.7490, -0.7333,  ..., -0.7569, -0.7412, -0.7961],\n",
       "          [-0.8667, -0.8510, -0.8196,  ..., -0.8039, -0.8118, -0.8588],\n",
       "          [-0.8980, -0.9059, -0.8824,  ..., -0.8824, -0.8824, -0.8902]],\n",
       " \n",
       "         [[-0.7647, -0.6392, -0.5608,  ..., -0.7804, -0.8745, -0.9373],\n",
       "          [-0.5686, -0.4275, -0.3725,  ..., -0.6235, -0.7098, -0.8275],\n",
       "          [-0.4431, -0.3020, -0.2314,  ..., -0.5294, -0.5922, -0.7176],\n",
       "          ...,\n",
       "          [-0.8118, -0.7333, -0.6941,  ..., -0.6078, -0.6078, -0.6863],\n",
       "          [-0.9137, -0.8824, -0.8353,  ..., -0.6941, -0.7098, -0.7804],\n",
       "          [-0.9451, -0.9608, -0.9373,  ..., -0.8353, -0.8275, -0.8431]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_gen=torch.Generator().manual_seed(42)\n",
    "\n",
    "trainDS, validDS, testDS = random_split(datasets,\n",
    "                                        [0.7, 0.1, 0.2],\n",
    "                                        generator=seed_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 36, 73)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDS), len(validDS), len(testDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DL = DataLoader(trainDS, batch_size=9)\n",
    "VALID_DL = DataLoader(validDS, batch_size=9)\n",
    "TEST_DL = DataLoader(testDS, batch_size=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[ 1.0000,  0.9608,  0.9451,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9686,  0.6235,  0.4118,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9686,  0.6078,  0.3569,  ...,  0.7020,  0.9686,  1.0000],\n",
      "          ...,\n",
      "          [ 0.9922,  0.5294, -0.4431,  ...,  0.7098,  1.0000,  1.0000],\n",
      "          [ 0.9922,  0.9451,  0.3490,  ...,  0.6941,  1.0000,  0.9922],\n",
      "          [ 0.9922,  1.0000,  0.9922,  ...,  0.9373,  1.0000,  0.9922]],\n",
      "\n",
      "         [[ 1.0000,  0.9608,  0.9451,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9686,  0.6314,  0.4275,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9686,  0.6235,  0.3725,  ...,  0.7020,  0.9686,  1.0000],\n",
      "          ...,\n",
      "          [ 0.9922,  0.5216, -0.4510,  ...,  0.7176,  1.0000,  1.0000],\n",
      "          [ 0.9843,  0.9373,  0.3412,  ...,  0.6471,  1.0000,  0.9922],\n",
      "          [ 0.9922,  1.0000,  0.9922,  ...,  0.9294,  1.0000,  0.9922]],\n",
      "\n",
      "         [[ 1.0000,  0.9529,  0.9373,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9686,  0.6863,  0.5137,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.9686,  0.7020,  0.4824,  ...,  0.6941,  0.9608,  1.0000],\n",
      "          ...,\n",
      "          [ 0.9922,  0.5137, -0.4588,  ...,  0.7412,  1.0000,  1.0000],\n",
      "          [ 0.9843,  0.9373,  0.3333,  ...,  0.6627,  1.0000,  0.9922],\n",
      "          [ 0.9922,  1.0000,  0.9922,  ...,  0.9294,  1.0000,  0.9922]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2627,  0.2706,  0.2627,  ...,  0.1451,  0.1451,  0.1373],\n",
      "          [ 0.2627,  0.2706,  0.2392,  ...,  0.1608,  0.1608,  0.1686],\n",
      "          [ 0.2706,  0.2627,  0.0431,  ...,  0.1451,  0.1608,  0.1529],\n",
      "          ...,\n",
      "          [-0.9529, -0.9451, -0.9451,  ...,  0.3176,  0.4588,  0.4353],\n",
      "          [-0.9451, -0.9451, -0.9451,  ...,  0.3490,  0.5137,  0.4824],\n",
      "          [-0.9373, -0.9529, -0.9451,  ...,  0.4510,  0.4902,  0.4431]],\n",
      "\n",
      "         [[-0.2314, -0.2157, -0.2157,  ..., -0.3333, -0.3333, -0.3333],\n",
      "          [-0.2314, -0.2078, -0.2157,  ..., -0.3333, -0.3333, -0.3412],\n",
      "          [-0.2235, -0.2000, -0.3176,  ..., -0.3333, -0.3412, -0.3412],\n",
      "          ...,\n",
      "          [-0.9608, -0.9608, -0.9529,  ..., -0.6863, -0.6314, -0.5922],\n",
      "          [-0.9529, -0.9608, -0.9608,  ..., -0.6784, -0.5843, -0.6314],\n",
      "          [-0.9451, -0.9608, -0.9529,  ..., -0.6314, -0.6471, -0.6706]],\n",
      "\n",
      "         [[-0.3725, -0.3804, -0.3804,  ..., -0.4745, -0.4745, -0.4745],\n",
      "          [-0.3725, -0.3725, -0.3882,  ..., -0.4667, -0.4667, -0.4667],\n",
      "          [-0.3725, -0.3647, -0.4431,  ..., -0.4745, -0.4745, -0.4745],\n",
      "          ...,\n",
      "          [-0.9137, -0.9137, -0.9137,  ..., -0.7020, -0.5843, -0.5294],\n",
      "          [-0.9059, -0.9137, -0.9137,  ..., -0.6863, -0.5137, -0.5843],\n",
      "          [-0.8980, -0.9137, -0.9059,  ..., -0.6392, -0.6314, -0.6627]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2941,  0.1686,  0.2000,  ..., -0.0275, -0.4431, -0.6706],\n",
      "          [ 0.3098,  0.2157,  0.2000,  ..., -0.0275, -0.2941, -0.7020],\n",
      "          [ 0.3333,  0.1529, -0.2157,  ..., -0.1137, -0.3412, -0.5451],\n",
      "          ...,\n",
      "          [-0.8745, -0.8824, -0.8902,  ..., -0.6235, -0.8824, -0.9216],\n",
      "          [-0.8824, -0.8745, -0.8902,  ..., -0.6784, -0.8980, -0.9294],\n",
      "          [-0.8980, -0.8980, -0.8980,  ..., -0.9137, -0.9294, -0.9373]],\n",
      "\n",
      "         [[ 0.3098,  0.1843,  0.2157,  ..., -0.0039, -0.4275, -0.6627],\n",
      "          [ 0.3255,  0.2314,  0.2157,  ..., -0.0118, -0.2706, -0.7020],\n",
      "          [ 0.3490,  0.1686, -0.1922,  ..., -0.0902, -0.3098, -0.5294],\n",
      "          ...,\n",
      "          [-0.8745, -0.8824, -0.8980,  ..., -0.6000, -0.8824, -0.9294],\n",
      "          [-0.8824, -0.8824, -0.8980,  ..., -0.6627, -0.9059, -0.9373],\n",
      "          [-0.9059, -0.9059, -0.9059,  ..., -0.9216, -0.9373, -0.9451]],\n",
      "\n",
      "         [[ 0.3098,  0.1843,  0.2078,  ..., -0.0118, -0.4353, -0.6627],\n",
      "          [ 0.3255,  0.2314,  0.2157,  ..., -0.0039, -0.2706, -0.7020],\n",
      "          [ 0.3490,  0.1765, -0.1922,  ..., -0.0980, -0.3098, -0.5294],\n",
      "          ...,\n",
      "          [-0.8824, -0.8824, -0.8980,  ..., -0.6078, -0.8902, -0.9294],\n",
      "          [-0.8824, -0.8824, -0.8980,  ..., -0.6627, -0.9059, -0.9373],\n",
      "          [-0.9059, -0.9059, -0.9059,  ..., -0.9216, -0.9373, -0.9451]]],\n",
      "\n",
      "\n",
      "        [[[-0.4510, -0.3882, -0.5294,  ..., -0.3569, -0.4431, -0.5059],\n",
      "          [-0.1529, -0.3412, -0.4667,  ..., -0.4745, -0.4431, -0.4745],\n",
      "          [-0.2000, -0.1843, -0.3255,  ..., -0.4588, -0.4902, -0.5137],\n",
      "          ...,\n",
      "          [ 0.2706, -0.0510, -0.0510,  ...,  0.8980,  0.8196,  0.7725],\n",
      "          [ 0.3020,  0.0353,  0.0510,  ...,  0.9294,  0.8902,  0.8353],\n",
      "          [ 0.3176,  0.1294,  0.0588,  ...,  0.9216,  0.8902,  0.8902]],\n",
      "\n",
      "         [[-0.4510, -0.3882, -0.5373,  ..., -0.3804, -0.4667, -0.5294],\n",
      "          [-0.1529, -0.3490, -0.4667,  ..., -0.4902, -0.4667, -0.4902],\n",
      "          [-0.2000, -0.1843, -0.3098,  ..., -0.4667, -0.5059, -0.5294],\n",
      "          ...,\n",
      "          [ 0.3490,  0.0588,  0.0667,  ...,  0.8745,  0.8196,  0.7804],\n",
      "          [ 0.3882,  0.1608,  0.1765,  ...,  0.9216,  0.8980,  0.8510],\n",
      "          [ 0.3647,  0.2157,  0.1529,  ...,  0.9216,  0.8980,  0.8980]],\n",
      "\n",
      "         [[-0.6706, -0.6392, -0.7647,  ..., -0.6314, -0.6941, -0.7176],\n",
      "          [-0.4510, -0.6235, -0.7176,  ..., -0.7098, -0.6863, -0.7020],\n",
      "          [-0.5059, -0.5059, -0.5922,  ..., -0.6784, -0.7020, -0.7255],\n",
      "          ...,\n",
      "          [ 0.0039, -0.1294, -0.0667,  ...,  0.7647,  0.6863,  0.6706],\n",
      "          [ 0.0588, -0.0118,  0.0431,  ...,  0.8824,  0.8510,  0.8118],\n",
      "          [ 0.0902,  0.0431,  0.0039,  ...,  0.8745,  0.8588,  0.8431]]],\n",
      "\n",
      "\n",
      "        [[[-0.5373, -0.5373, -0.5216,  ..., -0.9137, -0.9059, -0.9216],\n",
      "          [-0.4902, -0.5137, -0.4902,  ..., -0.8824, -0.8980, -0.9294],\n",
      "          [-0.5137, -0.5059, -0.4431,  ..., -0.7647, -0.8431, -0.9059],\n",
      "          ...,\n",
      "          [-0.7333, -0.8510, -0.9451,  ...,  0.0353, -0.7804, -0.8745],\n",
      "          [-0.4824, -0.7725, -0.8353,  ...,  0.0824, -0.7412, -0.8745],\n",
      "          [-0.3725, -0.7098, -0.7412,  ...,  0.0588, -0.7412, -0.8902]],\n",
      "\n",
      "         [[-0.6314, -0.6392, -0.6314,  ..., -0.9529, -0.9451, -0.9529],\n",
      "          [-0.5922, -0.6157, -0.5922,  ..., -0.9216, -0.9373, -0.9608],\n",
      "          [-0.6078, -0.6078, -0.5529,  ..., -0.8353, -0.9137, -0.9451],\n",
      "          ...,\n",
      "          [-0.8039, -0.8902, -0.9686,  ..., -0.4353, -0.8824, -0.8980],\n",
      "          [-0.6000, -0.8196, -0.8824,  ..., -0.3961, -0.8588, -0.9059],\n",
      "          [-0.5137, -0.7725, -0.7882,  ..., -0.4039, -0.8588, -0.9137]],\n",
      "\n",
      "         [[-0.6549, -0.6627, -0.6627,  ..., -0.6549, -0.6549, -0.6549],\n",
      "          [-0.6392, -0.6627, -0.6549,  ..., -0.6549, -0.6549, -0.6549],\n",
      "          [-0.6392, -0.6549, -0.6549,  ..., -0.6471, -0.6549, -0.6471],\n",
      "          ...,\n",
      "          [-0.5765, -0.5843, -0.6314,  ..., -0.6000, -0.6235, -0.6157],\n",
      "          [-0.4824, -0.5529, -0.5843,  ..., -0.5843, -0.6235, -0.6157],\n",
      "          [-0.4588, -0.5216, -0.5294,  ..., -0.5843, -0.6235, -0.6235]]]]), tensor([1, 0, 0, 1, 0, 0, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "for a in TRAIN_DL:\n",
    "    print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "model = CNN(num_classes=3)  # Assuming you have 10 classes\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.8613, Train Accuracy: 0.5073, Valid Loss: 0.9182, Valid Accuracy: 0.5278\n",
      "Epoch [2/20], Train Loss: 0.8342, Train Accuracy: 0.4950, Valid Loss: 0.9157, Valid Accuracy: 0.3889\n",
      "Epoch [3/20], Train Loss: 0.8144, Train Accuracy: 0.4958, Valid Loss: 0.8569, Valid Accuracy: 0.5556\n",
      "Epoch [4/20], Train Loss: 0.7690, Train Accuracy: 0.5563, Valid Loss: 0.8598, Valid Accuracy: 0.5278\n",
      "Epoch [5/20], Train Loss: 0.7381, Train Accuracy: 0.6023, Valid Loss: 0.8798, Valid Accuracy: 0.4722\n",
      "Epoch [6/20], Train Loss: 0.6981, Train Accuracy: 0.6291, Valid Loss: 0.9316, Valid Accuracy: 0.5278\n",
      "Epoch [7/20], Train Loss: 0.6467, Train Accuracy: 0.6789, Valid Loss: 0.9709, Valid Accuracy: 0.5556\n",
      "Epoch [8/20], Train Loss: 0.5748, Train Accuracy: 0.7364, Valid Loss: 1.0764, Valid Accuracy: 0.6111\n",
      "Epoch [9/20], Train Loss: 0.4952, Train Accuracy: 0.7862, Valid Loss: 1.1308, Valid Accuracy: 0.5556\n",
      "Epoch [10/20], Train Loss: 0.4028, Train Accuracy: 0.8429, Valid Loss: 1.1917, Valid Accuracy: 0.5278\n",
      "Epoch [11/20], Train Loss: 0.3146, Train Accuracy: 0.8659, Valid Loss: 1.2847, Valid Accuracy: 0.5556\n",
      "Epoch [12/20], Train Loss: 0.2362, Train Accuracy: 0.9080, Valid Loss: 1.2643, Valid Accuracy: 0.5556\n",
      "Epoch [13/20], Train Loss: 0.1866, Train Accuracy: 0.9395, Valid Loss: 1.3763, Valid Accuracy: 0.5556\n",
      "Epoch [14/20], Train Loss: 0.1297, Train Accuracy: 0.9617, Valid Loss: 1.3729, Valid Accuracy: 0.5833\n",
      "Epoch [15/20], Train Loss: 0.1772, Train Accuracy: 0.9540, Valid Loss: 1.5041, Valid Accuracy: 0.5278\n",
      "Epoch [16/20], Train Loss: 0.1676, Train Accuracy: 0.9349, Valid Loss: 1.9965, Valid Accuracy: 0.4722\n",
      "Epoch [17/20], Train Loss: 0.1625, Train Accuracy: 0.9464, Valid Loss: 2.2858, Valid Accuracy: 0.5278\n",
      "Epoch [18/20], Train Loss: 0.1249, Train Accuracy: 0.9579, Valid Loss: 1.8659, Valid Accuracy: 0.5556\n",
      "Epoch [19/20], Train Loss: 0.0669, Train Accuracy: 0.9923, Valid Loss: 1.8581, Valid Accuracy: 0.6111\n",
      "Epoch [20/20], Train Loss: 0.0643, Train Accuracy: 0.9885, Valid Loss: 1.9638, Valid Accuracy: 0.6111\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "\n",
    "    for inputs, labels in TRAIN_DL:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_accuracy += (predicted == labels).sum().item() / labels.size(0)\n",
    "        torch.save(model.state_dict(), 'albumart_model.pth')  # Add this line after training \n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_accuracy = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in VALID_DL:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            valid_accuracy += (predicted == labels).sum().item() / labels.size(0)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss/len(TRAIN_DL):.4f}, Train Accuracy: {train_accuracy/len(TRAIN_DL):.4f}, Valid Loss: {valid_loss/len(VALID_DL):.4f}, Valid Accuracy: {valid_accuracy/len(VALID_DL):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.1646, Test Accuracy: 0.5556\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_accuracy = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in TEST_DL:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_accuracy += (predicted == labels).sum().item() / labels.size(0)\n",
    "\n",
    "print(f'Test Loss: {test_loss/len(TEST_DL):.4f}, Test Accuracy: {test_accuracy/len(TEST_DL):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
